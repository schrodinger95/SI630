{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI630 Homework 2: Word2vec Vector Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('bios_med_batch_256_epoch_4.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20165895, -0.01813876,  0.1750827 ,  0.09639848, -0.02201944,\n",
       "        0.18369845,  0.01794782,  0.00295165,  0.11931761, -0.10448378,\n",
       "        0.01803998, -0.07901689, -0.10488269,  0.00539323, -0.03110824,\n",
       "       -0.07133382, -0.02910757, -0.0789279 ,  0.14662962,  0.08217697,\n",
       "        0.1421855 ,  0.01343828,  0.19392279, -0.00386903,  0.04829562,\n",
       "        0.12131953,  0.24014181, -0.13736582, -0.15497984,  0.06881718,\n",
       "        0.10854956, -0.105537  , -0.07303723,  0.13146509,  0.23141602,\n",
       "       -0.1144508 ,  0.20217368,  0.03196618, -0.06661914, -0.17894885,\n",
       "        0.02781994, -0.0405029 ,  0.16767456, -0.13433322,  0.14217737,\n",
       "        0.1244102 , -0.00829909,  0.00078837,  0.17730832,  0.10820755],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('articles', 0.9301235675811768),\n",
       " ('stories', 0.9001354575157166),\n",
       " ('chapters', 0.8929038643836975),\n",
       " ('essays', 0.8909899592399597),\n",
       " ('poems', 0.8849905133247375),\n",
       " ('pieces', 0.8777825832366943),\n",
       " ('novels', 0.8777396082878113),\n",
       " ('publications', 0.8739532232284546),\n",
       " ('works', 0.8672537803649902),\n",
       " ('songs', 0.8622357845306396)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 0.9290370941162109),\n",
       " ('4', 0.9143548607826233),\n",
       " ('00', 0.9067174792289734),\n",
       " ('6', 0.897883951663971),\n",
       " ('2', 0.8939003348350525),\n",
       " ('5', 0.8930113315582275),\n",
       " ('7', 0.8728490471839905),\n",
       " ('mtr', 0.8726956844329834),\n",
       " ('kos', 0.8707765936851501),\n",
       " ('8', 0.8698921203613281)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1999', 0.9925663471221924),\n",
       " ('1995', 0.9869691133499146),\n",
       " ('1998', 0.9850436449050903),\n",
       " ('2001', 0.9791236519813538),\n",
       " ('1994', 0.9743227958679199),\n",
       " ('1993', 0.9683092832565308),\n",
       " ('2002', 0.9671524167060852),\n",
       " ('1990', 0.9638951420783997),\n",
       " ('2003', 0.9552311897277832),\n",
       " ('1996', 0.9541018009185791)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"1997\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('director', 0.898308515548706),\n",
       " ('executive', 0.8812198638916016),\n",
       " ('editor_in_chief', 0.8532493710517883),\n",
       " ('berkshire_hathaway', 0.8505509495735168),\n",
       " ('initiation', 0.8462409377098083),\n",
       " ('manuel_valls', 0.8398170471191406),\n",
       " ('copywriter', 0.8368911743164062),\n",
       " ('publisher', 0.8360226154327393),\n",
       " ('editorial', 0.8333226442337036),\n",
       " ('conductor', 0.8304686546325684)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"editor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('month', 0.8269412517547607),\n",
       " ('yr', 0.7702096700668335),\n",
       " ('same', 0.7489410042762756),\n",
       " ('week', 0.7207983136177063),\n",
       " ('following', 0.7093653678894043),\n",
       " ('cut', 0.6853080987930298),\n",
       " ('annexe', 0.6761999130249023),\n",
       " ('batch', 0.6696181893348694),\n",
       " ('regnal', 0.6693113446235657),\n",
       " ('contract', 0.6571323275566101)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('italian', 0.9046142101287842),\n",
       " ('indian', 0.8832364082336426),\n",
       " ('australian', 0.8807172775268555),\n",
       " ('german', 0.8787484765052795),\n",
       " ('mexican', 0.8701288104057312),\n",
       " ('canadian', 0.870055615901947),\n",
       " ('chinese', 0.8655357956886292),\n",
       " ('russian', 0.8644894361495972),\n",
       " ('african', 0.8623622059822083),\n",
       " ('irish', 0.8586634993553162)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"american\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malaysian', 0.956145703792572),\n",
       " ('taiwanese', 0.948494017124176),\n",
       " ('colombian', 0.9470311403274536),\n",
       " ('luxembourgian', 0.9336711764335632),\n",
       " ('chilean', 0.9333783984184265),\n",
       " ('volleyball_player', 0.9329121708869934),\n",
       " ('tunisian', 0.9303444623947144),\n",
       " ('kuwaiti', 0.9272135496139526),\n",
       " ('ecuadorian', 0.9270731210708618),\n",
       " ('belarusian', 0.9270274043083191)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"singaporean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('alabama', 0.9656677842140198),\n",
       " ('maryland', 0.9638500213623047),\n",
       " ('iowa', 0.961591362953186),\n",
       " ('nebraska', 0.960230827331543),\n",
       " ('indiana', 0.9586057662963867),\n",
       " ('texas', 0.9499304890632629),\n",
       " ('ohio', 0.9489908218383789),\n",
       " ('pennsylvania', 0.9428957104682922),\n",
       " ('wisconsin', 0.9426720142364502),\n",
       " ('illinois', 0.9417473673820496)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"michigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mathematics', 0.9871182441711426),\n",
       " ('biology', 0.9829882979393005),\n",
       " ('geology', 0.978592038154602),\n",
       " ('sociology', 0.976425051689148),\n",
       " ('psychology', 0.9705943465232849),\n",
       " ('electrical_engineering', 0.967595100402832),\n",
       " ('theology', 0.9649304747581482),\n",
       " ('physics', 0.9648690223693848),\n",
       " ('philosophy', 0.9559603929519653),\n",
       " ('biochemistry', 0.9555490016937256)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"chemistry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('funny', 0.9575430750846863),\n",
       " ('shit', 0.9288731813430786),\n",
       " ('tells', 0.9229275584220886),\n",
       " ('love', 0.9159948825836182),\n",
       " ('wonder', 0.9153821468353271),\n",
       " ('merry', 0.9139838814735413),\n",
       " ('slice', 0.9085487127304077),\n",
       " ('urban_fantasy', 0.9039624929428101),\n",
       " ('autobiographical', 0.9037138819694519),\n",
       " ('oum', 0.9031621813774109)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('healthcare', 0.9702292084693909),\n",
       " ('energy', 0.9652633666992188),\n",
       " ('technologies', 0.9649089574813843),\n",
       " ('preservation', 0.959334671497345),\n",
       " ('conservation', 0.9559587836265564),\n",
       " ('regulatory', 0.9551090002059937),\n",
       " ('export', 0.9548025727272034),\n",
       " ('infrastructure', 0.9515159130096436),\n",
       " ('consumer', 0.9475796818733215),\n",
       " ('markets', 0.9471139907836914)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"sustainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('congo', 0.9102293252944946),\n",
       " ('commonwealth', 0.908725380897522),\n",
       " ('democracy', 0.900790274143219),\n",
       " ('representing', 0.8999566435813904),\n",
       " ('pakistan', 0.87607342004776),\n",
       " ('nepal', 0.8726961612701416),\n",
       " ('congress', 0.8671219944953918),\n",
       " ('ukraine', 0.8636444807052612),\n",
       " ('democratic', 0.8612542152404785),\n",
       " ('armenia', 0.8581361174583435)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"republic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model determines that the similar words are semantically similar to the target words. For words with different frequency of occurrence, the model has different prediction effects. <br/>\n",
    "For example, for the same number prediction, the prediction for \"1997\" was excellent, while for an overly common word like \"1\", there were several results that were not numbers.<br/> \n",
    "For words that occur occasionally, sometimes the model predicts very well , such as \"Singaporean\", and sometimes the predictions lacks relevance to the target word, such as for \"sustainable\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    return word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('man', 'king', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('book', 'person', 'books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'five'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('1', 'one', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beijing'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('korea', 'china', 'seoul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('i', 'you', 'my')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gymnastics'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_analogy('walk', 'swim', 'walking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the analogies predicted by the model are correct, while others are not.<br/> \n",
    "For the correspondence of nouns, my model does a better job, such as the correspondence between countries and capitals. Whereas when it comes to lexical transformations, such as the plural form of nouns and the progressive tense of verbs, my model's predictions fail more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Username on CodaLab: rugexu*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('bios_med_batch_256_debiased.kv', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair = pd.read_csv('word_pair_similarity_predictions.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>-0.247691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>0.737122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>0.789920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>0.842529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.769365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2       sim\n",
       "0    old          new -0.247691\n",
       "1  smart  intelligent  0.737122\n",
       "2   hard    difficult  0.789920\n",
       "3  happy     cheerful  0.842529\n",
       "4   hard         easy  0.769365"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, row in word_pair.iterrows():\n",
    "    word1 = row[0].lower().replace(' ', '_')\n",
    "    word2 = row[1].lower().replace(' ', '_')\n",
    "    if word1 not in word_vectors:\n",
    "        word1 = '<UNK>'\n",
    "    if word2 not in word_vectors:\n",
    "        word2 = '<UNK>'\n",
    "    word_pair.loc[index, 'sim'] = word_vectors.similarity(word1, word2)\n",
    "\n",
    "word_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pair.to_csv('word_pair_similarity_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
